{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BigQuery Sample Codes  \n",
    "AIDP 분석환경에서 제공하는 JupyerHub에서 skt 파이썬 패키지를 사용하면 BigQuery와 연동하여 분석 및 모델링 작업을 수행할 수 있습니다.  \n",
    "skt 패키지는 분석환경에 기본적으로 설치되어 있으며 pip를 사용하여 버전 업그레이드를 할 수 있습니다.\n",
    "~~~bash\n",
    "$ pip install --upgrade skt\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BigQuery 실행  \n",
    "다음과 같이 2가지 방법으로 쿼리를 실행하고 결과를 확인할 수 있습니다.  \n",
    "- IPython Magic을 사용하여 Jupyter Notebook Cell에서 SQL 실행\n",
    "- BigQuery Client 사용하여 SQL 실행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IPython Magic으로 SQL 실행  \n",
    "Jupyter Notebook Cell에서 SQL을 실행하고 그 결과를 확인할 수 있습니다. 쿼리 결과는 변수에 Pandas Dataframe으로 저장할 수 있습니다. Ditonary로 정의된 쿼리 파라미터를 SQL에 주입할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "먼저, IPython Magic을 로드합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skt.gcp import load_bigquery_ipython_magic\n",
    "\n",
    "load_bigquery_ipython_magic()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음과 같이 SQL을 실행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bq\n",
    "    SELECT MAX(dt) as max_dt\n",
    "    FROM tworld.twd_dst_product_group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SQL 결과를 Pandas DataFrame으로 변수에 저장할 수 있습니다. 다음은 max_dt라는 변수에 SQL 결과를 저장하는 예제입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skt.ye import get_spark\n",
    "from skt.gcp import load_bigquery_ipython_magic, \\\n",
    "                    bq_to_pandas, \\\n",
    "                    get_bigquery_client\n",
    "\n",
    "load_bigquery_ipython_magic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bq max_dt\n",
    "\n",
    "SELECT MAX(dt) as value\n",
    "FROM tworld.twd_dst_product_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "쿼리 파라미터를 SQL에 전달할 수 있습니다. 전달할 값은 Dictionary 타입으로 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_params = {\n",
    "    \"max_dt\": max_dt[\"value\"][0].strftime(\"%Y-%m-%d\")\n",
    "}\n",
    "\n",
    "query_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음과 같이 params 옵션에 전달할 쿼리 파라미터 변수를 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bq --params $query_params\n",
    "\n",
    "SELECT *\n",
    "FROM tworld.twd_dst_product_group\n",
    "WHERE dt = '{max_dt}'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BigQuery Client로 SQL 실행  \n",
    "BigQuery Client는 Google에서 제공하는 Client Library에서 제공하는 객체입니다. SQL을 실행할 수 있을 뿐만 아니라 Google Client Library에서 제공하는 다양한 기능들을 활용할 수 있습니다. 더욱 자세한 내용은 <a href=\"https://googleapis.dev/python/bigquery/latest/generated/google.cloud.bigquery.client.Client.html#google.cloud.bigquery.client.Client\" target=\"_blank\">이곳</a>에서 확인하시기 바랍니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음과 같이 BigQuery Client를 생성하여 SQL을 실행합니다. 쿼리 조회 결과가 있는 경우 Iterator 형태로 결과를 리턴해줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skt.gcp import get_bigquery_client\n",
    "\n",
    "bq_client = get_bigquery_client()\n",
    "\n",
    "sql = \"\"\"\n",
    "    SELECT *\n",
    "    FROM tworld.twd_dst_product_group\n",
    "    WHERE dt = '{max_dt}'\n",
    "    LIMIT 5\n",
    "\"\"\".format(**query_params)\n",
    "\n",
    "iterator = bq_client.query(sql).result()\n",
    "for r in iterator:\n",
    "    product_grp_id, product_grp_nm, dt = r\n",
    "    print(product_grp_id, product_grp_nm, dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INSERT OVERWRITE\n",
    "BigQuery는 Hive와 달리 INSERT OVERWRITE 기능을 제공하지 않습니다. 그러나 skt 패키지의 bq_insert_overwrite 메서드를 사용하면 INSERT OVERWRITE가 가능합니다.  \n",
    "만약 테이블이 존재하지 않는다면 새로 테이블을 생성합니다.  \n",
    "저장하려는 대상 테이블이 파티셔닝되어 있다면 partition 파라미터를 사용하여 파티션 컬럼 이름을 설정합니다. sql 결과의 파티션 컬럼 값에 따라 해당 파티션으로 저장됩니다.  \n",
    "대상 테이블이 cluster 설정이 되어 있거나 새로 생성하는 테이블에 clustrer를 설정하고 싶은 경우 clustering_fields 파라미터에 컬럼 이름을 리스트로 넣어줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skt.gcp import bq_insert_overwrite, get_temp_table\n",
    "\n",
    "sql = \"\"\"\n",
    "    SELECT *\n",
    "    FROM tworld.twd_dst_product_group\n",
    "    WHERE dt = '{max_dt}'\n",
    "\"\"\".format(**query_params)\n",
    "\n",
    "result_table_name= get_temp_table()\n",
    "\n",
    "bq_insert_overwrite(sql=sql, destination=result_table_name, partition=\"dt\", clustering_fields=[\"product_grp_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Partitions\n",
    "BigQuery는 단일 컬럼 파티션만 제공합니다. BigQuery에서 멀티 파티션 컬럼을 사용할 수는 없지만 BigQuery에서 제공하는 와일드카드 테이블을 응용하여 멀티 파티션 테이블처럼 정의할 수 있습니다.  \n",
    "<b>\"__\"</b>를 구분자로 한 테이블들을 생성하여 멀티 파티션처럼 사용하는 예제입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bq --params $query_params\n",
    "\n",
    "CREATE OR REPLACE TABLE temp_1d.wildcard_table__subpart_1\n",
    "AS\n",
    "SELECT *\n",
    "FROM tworld.twd_dst_product_group\n",
    "WHERE dt = '{max_dt}'\n",
    ";\n",
    "\n",
    "CREATE OR REPLACE TABLE temp_1d.wildcard_table__subpart_2\n",
    "AS\n",
    "SELECT *\n",
    "FROM tworld.twd_dst_product_group\n",
    "WHERE dt = '{max_dt}'\n",
    ";\n",
    "\n",
    "SELECT *\n",
    "FROM `temp_1d.wildcard_table__*`\n",
    "WHERE _TABLE_SUFFIX = 'subpart_1'\n",
    "LIMIT 5\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이렇게 와일드카드로 생성한 테이블들에도 INSERT OVERWRITE를 사용할 수 있습니다. skt 패키지의 bq_insert_overwrite_with_suffixes 메서드를 사용하여 특정 suffix를 가지는 테이블의 특정 파티션에 INSERT OVERWRITE 할 수 있습니다. 마치 멀티 파티션 테이블에 데이터를 저장하는 것처럼 말입니다.  \n",
    "아래와 같이 suffixes 파라미터에 추가 파티션으로 사용할 컬럼 이름을 지정합니다. suffix가 여러 개인 경우(예: table_name__subpart1__subpart2)도 suffixes 파라미터에 해당 컬럼 이름들을 리스트로 넣어주면 INSERT OVERWRITE 할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skt.gcp import bq_insert_overwrite, get_temp_table\n",
    "\n",
    "sql = \"\"\"\n",
    "    SELECT *, 'subpart_1' as subpart\n",
    "    FROM tworld.twd_dst_product_group\n",
    "    WHERE dt = '{max_dt}'\n",
    "\"\"\".format(**query_params)\n",
    "\n",
    "result_table_name= get_temp_table()\n",
    "\n",
    "bq_insert_overwrite(sql=sql, destination=result_table_name, suffixes=[\"subpart\"], partition=\"dt\", clustering_fields=[\"product_grp_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-07-24T10:37:32.896007Z",
     "iopub.status.busy": "2020-07-24T10:37:32.895729Z",
     "iopub.status.idle": "2020-07-24T10:37:32.899963Z",
     "shell.execute_reply": "2020-07-24T10:37:32.899185Z",
     "shell.execute_reply.started": "2020-07-24T10:37:32.895978Z"
    }
   },
   "source": [
    "## BigQuery to Pandas\n",
    "위에서 설명했듯이 BigQuery 쿼리 결과를 Pandas Dataframe으로 리턴받을 수 있습니다.\n",
    "위의 IPython Magic 뿐만 아니라 skt 패키지에서 제공하는 메서드를 사용할 수도 있습니다.   \n",
    "   \n",
    "(참고 : Jupyter Notebook Cell에서 IPyhon Magic을 사용하여 SQL을 실행하는 경우 그 Cell에는 다른 Python 코드를 추가할 수 없습니다. Cell에 다른 Python 코드를 자유롭게 추가하려면 skt 패키지의 기능을 활용하시기 바랍니다.)\n",
    "\n",
    "\n",
    "다음은 bq_to_pandas 메서드로 결과를 Pandas Dataframe에 저장하는 예입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skt.gcp import bq_to_pandas\n",
    "\n",
    "pd_df = bq_to_pandas(\"\"\"\n",
    "    SELECT *\n",
    "    FROM tworld.twd_dst_product_group\n",
    "    WHERE dt = (SELECT MAX(dt) FROM tworld.twd_dst_product_group)\n",
    "\"\"\")\n",
    "\n",
    "pd_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-07-24T10:37:38.855128Z",
     "iopub.status.busy": "2020-07-24T10:37:38.854849Z",
     "iopub.status.idle": "2020-07-24T10:37:38.858801Z",
     "shell.execute_reply": "2020-07-24T10:37:38.858133Z",
     "shell.execute_reply.started": "2020-07-24T10:37:38.855101Z"
    }
   },
   "source": [
    "## Pandas to BigQuery\n",
    "\n",
    "Pandas Dataframe을 특정 BigQuery 테이블에 저장할 수 있습니다.  \n",
    "다음과 같이 pandas_to_bq 메서드를 사용합니다. destination 파라미터에 BigQuery 테이블을 지정해주며 테이블이 없는 경우 자동으로 생성됩니다.  \n",
    "destination 테이블에 파티션이 있다면 Pandas Dataframe에서 자동으로 컬럼 이름을 감지하여 해당 파티션에 저장합니다.  \n",
    "destination 테이블을 새로 생성하는 경우 partition 파라미터에 파티션으로 사용할 컬럼 이름을 지정해주어 파티셔닝된 테이블을 생성할 수 있습니다.  \n",
    "또한 clustering_fields 파라미터를 사용하여 클러스터링에 사용할 컬럼을 지정할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from skt.gcp import pandas_to_bq\n",
    "\n",
    "dest_table = f\"twd_dst_product_group_{str(int(time.time()))}\"\n",
    "print(f\"저장할 테이블 : temp_1d.{dest_table}\")\n",
    "\n",
    "pandas_to_bq(\n",
    "    pd_df=pd_df, \n",
    "    destination=f\"sktaic-datahub.temp_1d.{dest_table}\",\n",
    "    partition=\"dt\",\n",
    "    clustering_fields=[\"product_grp_id\"]\n",
    ")\n",
    "\n",
    "get_bigquery_client().query(f\"\"\"\n",
    "    SELECT *\n",
    "    FROM temp_1d.{dest_table}\n",
    "\"\"\").result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터가 테이블에 저장되었는지 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_params =  {\"dest_table\": dest_table}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bq --params $query_params\n",
    "\n",
    "SELECT *\n",
    "FROM temp_1d.{dest_table}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BigQuery to Spark  \n",
    "\n",
    "BigQuery 데이터를 가져와서 Spark로 처리할 수 있습니다. BigQuery SQL 결과를 Spark Dataframe으로 변환한 후 이어서 데이터 처리가 가능합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skt.gcp import bq_to_df\n",
    "\n",
    "spark_df = bq_to_df(f\"\"\"\n",
    "    SELECT *\n",
    "    FROM temp_1d.{dest_table}\n",
    "\"\"\")\n",
    "\n",
    "spark_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-07-24T10:49:31.530489Z",
     "iopub.status.busy": "2020-07-24T10:49:31.530234Z",
     "iopub.status.idle": "2020-07-24T10:49:31.534439Z",
     "shell.execute_reply": "2020-07-24T10:49:31.533990Z",
     "shell.execute_reply.started": "2020-07-24T10:49:31.530464Z"
    }
   },
   "source": [
    "## Spark to BigQuery  \n",
    "\n",
    "Spark으로 처리한 결과를 다시 BigQuery에 적재가 가능합니다.  \n",
    "다음은 위에서 spark_df 변수에 저장한 Spark Dataframe을 다시 BigQuery에 적재하는 예제입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 먼저 저장할 테이블을 BigQuery에 생성합니다. 여기서는 파티션된 테이블을 생성하고 특정 파티션에 Spark Dataframe을 저장할 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skt.gcp import df_to_bq_table\n",
    "from pyspark.sql.types import DateType\n",
    "\n",
    "dest_dataset = \"temp_1d\"\n",
    "partitioned_dest_table = f\"twd_dst_product_group_{str(int(time.time()))}\"\n",
    "\n",
    "get_bigquery_client().query(f\"\"\"\n",
    "    CREATE OR REPLACE TABLE {dest_dataset}.{partitioned_dest_table}\n",
    "    (\n",
    "        product_grp_id STRING,\n",
    "        product_grp_nm STRING,\n",
    "        dt DATE\n",
    "    )\n",
    "    PARTITION BY dt\n",
    "\"\"\").result()\n",
    "\n",
    "print(f\"생성된 테이블 : {dest_dataset}.{partitioned_dest_table}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Spark Dataframe을 BigQuery 테이블에 저장합니다. 여기서는 파티션 컬럼 타입이 Date이므로 타입 변환 작업을 해주었습니다. 이렇게 경우에 따라 타입 변환 작업이 필요한 경우가 있으므로 타입에 주의해주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "changed_df = spark_df.select(\"product_grp_id\", \"product_grp_nm\", spark_df.dt.cast(\"date\"))\n",
    "partition_dt = changed_df.head(1)[0].dt.strftime(\"%Y%m%d\")\n",
    "df_to_bq_table(df=changed_df,\n",
    "               dataset=dest_dataset,\n",
    "               table_name=partitioned_dest_table,\n",
    "               partition=partition_dt,\n",
    "               partition_field=\"dt\",\n",
    "               mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-07-24T11:22:22.034343Z",
     "iopub.status.busy": "2020-07-24T11:22:22.034091Z",
     "iopub.status.idle": "2020-07-24T11:22:24.605871Z",
     "shell.execute_reply": "2020-07-24T11:22:24.605324Z",
     "shell.execute_reply.started": "2020-07-24T11:22:22.034319Z"
    }
   },
   "source": [
    "3. BigQuery에 저장되었는지 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_params = {\"dataset\":dest_dataset, \"table_name\":partitioned_dest_table}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bq --params $query_params\n",
    "    SELECT *\n",
    "    FROM {dataset}.{table_name}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
